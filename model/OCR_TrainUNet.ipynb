{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "838f156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import random\n",
    "random.seed = 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b78b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 128\n",
    "root_dir = \"/home/ubuntu/Arrun/Combined_AnnotatedOCRText/\"\n",
    "img_dir = os.path.join(root_dir,\"images_SR\")\n",
    "segmap_img_dir = os.path.join(root_dir,\"segmaps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4658b3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining other metrics:\n",
    "def psnr(y_true,y_pred):\n",
    "    return tf.image.psnr(y_true,y_pred,1.0)\n",
    "def ssim(y_true,y_pred):\n",
    "    return tf.image.ssim(y_true,y_pred,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1193245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 15:37:36.976315: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-05 15:37:37.029107: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-05 15:37:37.797338: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "581365fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_randomized_filenames(directory_path):\n",
    "    filenames = os.listdir(directory_path)\n",
    "    random.shuffle(filenames)\n",
    "    return filenames\n",
    "\n",
    "# Example usage:\n",
    "directory_path = root_dir+\"/images_SR\"\n",
    "randomized_filenames = get_randomized_filenames(directory_path)\n",
    "\n",
    "split_index = len(randomized_filenames)*9//10\n",
    "train_filenames, val_filenames = randomized_filenames[:split_index],randomized_filenames[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "039b704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare training images\n",
    "def load_images(filenames, batch_size, batch_number):\n",
    "    os.chdir(img_dir)\n",
    "    in_img = []\n",
    "        \n",
    "    for i in filenames[batch_size*batch_number:batch_size*(batch_number+1)]:\n",
    "        if(i.endswith('.png')):\n",
    "            in_img.append(cv2.resize(cv2.imread(i),(input_size,input_size))[:,:,::-1]/255)\n",
    "            \n",
    "    return np.array(in_img, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13464bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare training images\n",
    "def load_segmasks(filenames,batch_size,batch_number):\n",
    "    segmasks = []\n",
    "    \n",
    "    new_filenames = [f'segmap_{i.split(\"_\")[1]}' for i in filenames[batch_size*batch_number:batch_size*(batch_number+1)]]\n",
    "    os.chdir(segmap_img_dir)\n",
    "        \n",
    "    for i in new_filenames:\n",
    "        if(i.endswith('.png')):\n",
    "            segmasks.append(cv2.resize(cv2.imread(i,cv2.IMREAD_GRAYSCALE),(input_size,input_size))/255)\n",
    "    \n",
    "    return np.array(to_categorical(segmasks,num_classes = 2), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbd5c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_number = 3\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = [load_images(train_filenames,batch_size,batch_number),load_segmasks(train_filenames,batch_size,batch_number)]\n",
    "for i in range(batch_size):\n",
    "    plt.figure(figsize = (18,12))\n",
    "    plt.subplot(1,3,1).imshow(train_dataset[0][i])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,2).imshow(np.argmax(train_dataset[1][i],axis = 2),cmap = 'gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d01286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    # Middle\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "\n",
    "    # Decoder\n",
    "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
    "    up5 = Conv2D(256, 2, activation='relu', padding='same')(up5)\n",
    "    merge5 = concatenate([conv3, up5], axis=3)  # Concatenate before and after\n",
    "    conv5 = Conv2D(256, 3, activation='relu', padding='same')(merge5)\n",
    "    conv5 = Conv2D(256, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
    "    up6 = Conv2D(128, 2, activation='relu', padding='same')(up6)\n",
    "    merge6 = concatenate([conv2, up6], axis=3)  # Concatenate before and after\n",
    "    conv6 = Conv2D(128, 3, activation='relu', padding='same')(merge6)\n",
    "    conv6 = Conv2D(128, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    up7 = Conv2D(64, 2, activation='relu', padding='same')(up7)\n",
    "    merge7 = concatenate([conv1, up7], axis=3)  # Concatenate before and after\n",
    "    conv7 = Conv2D(64, 3, activation='relu', padding='same')(merge7)\n",
    "    conv7 = Conv2D(64, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    outputs = Conv2D(num_classes, 1, activation='softmax')(conv7)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (input_size, input_size, 3)  # Example input shape\n",
    "num_classes = 2  # Example number of classes\n",
    "\n",
    "# Create the U-Net model\n",
    "model = unet(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adamax', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e17f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=(0, 1, 2))\n",
    "    union = tf.reduce_sum(y_true, axis=(0, 1, 2)) + tf.reduce_sum(y_pred, axis=(0, 1, 2))\n",
    "    dice = (2.0 * intersection + 1e-7) / (union + 1e-7)\n",
    "    mean_dice = tf.reduce_mean(dice[:num_classes])\n",
    "    return mean_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feabc96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(mask1, mask2):\n",
    "    # Compute the intersection\n",
    "    intersection = np.sum(np.logical_and(mask1, mask2))\n",
    "\n",
    "    # Compute the union\n",
    "    union = np.sum(np.logical_or(mask1, mask2))\n",
    "\n",
    "    # Calculate the IoU\n",
    "    iou = intersection / (union+1e-8)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24accf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Images = 1513, \n",
      "Total Val Images = 169, \n",
      "Val_batch_size : 84, \n",
      "Batch_size : 100,\n",
      "Num_visits : 5000\n",
      "Total_train_epochs : 70000,\n",
      "Start_batch_number : 1,\n",
      "Max_batch_number : 14\n"
     ]
    }
   ],
   "source": [
    "count_train_images = len(train_filenames)\n",
    "count_val_images = len(val_filenames)\n",
    "factor = 2\n",
    "val_batch_size = count_val_images//factor\n",
    "batch_size = 100\n",
    "num_visits = batch_size*50\n",
    "batch_number = 1\n",
    "max_batch_number = count_train_images//batch_size - 1\n",
    "total_train_epochs = max_batch_number*num_visits\n",
    "\n",
    "print(f\"Total Train Images = {count_train_images}, \\nTotal Val Images = {count_val_images}, \\nVal_batch_size : {val_batch_size}, \\nBatch_size : {batch_size},\\nNum_visits : {num_visits}\\nTotal_train_epochs : {total_train_epochs},\\nStart_batch_number : {batch_number},\\nMax_batch_number : {max_batch_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0549399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f4c4292",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgdir = \"/home/ubuntu/Arrun/OCRTestData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dbda57ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(test_imgdir)\n",
    "test_img = []\n",
    "test_filenames = os.listdir(test_imgdir)\n",
    "for i in test_filenames:\n",
    "    if(i.endswith('.png')):\n",
    "        test_img.append(cv2.resize(cv2.imread(i),(input_size,input_size))[:,:,::-1]/255)\n",
    "\n",
    "test_img = np.array(test_img, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ccf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val_dice = 0\n",
    "\n",
    "for i in range(total_train_epochs):\n",
    "    print(f\"Iteration {i}\")\n",
    "    train_dataset = [load_images(train_filenames,batch_size,batch_number),load_segmasks(train_filenames,batch_size,batch_number)]\n",
    "    print(f\"Training on Batch {batch_number}\")\n",
    "    print(\"Loaded\", np.array(train_dataset[0]).shape, np.array(train_dataset[1]).shape)\n",
    "    model.fit(np.array(train_dataset[0]),np.array(train_dataset[1]),batch_size = 1, epochs = 1)\n",
    "    \n",
    "    del train_dataset\n",
    "    gc.collect()\n",
    "    \n",
    "    if(batch_number == max_batch_number):\n",
    "        batch_number = 1\n",
    "    else:\n",
    "        batch_number += 1\n",
    "        \n",
    "        \n",
    "    if(i % max_batch_number == 0 and i!= 0):\n",
    "        print(f\"{i} epochs complete\")\n",
    "        val_iou = []\n",
    "        #val_class_iou = []\n",
    "        mean_val_dice = 0\n",
    "        for v in range(factor):\n",
    "            validation_dataset = [load_images(val_filenames,val_batch_size,v),load_segmasks(val_filenames,val_batch_size,v)]\n",
    "            val_preds = model.predict(validation_dataset[0],batch_size = 1)\n",
    "            for j in range(len(val_preds)):\n",
    "                val_iou.append(compute_iou(np.argmax(val_preds[j],axis = 2),np.argmax(validation_dataset[1][j],axis = 2)))\n",
    "                #val_class_iou.append(class_wise_iou(to_categorical(np.argmax(val_preds[j],axis = 2),num_classes = num_classes),validation_dataset[1][j]))\n",
    "            mean_val_dice = (v*mean_val_dice + np.array(dice_coefficient(val_preds, validation_dataset[1]).cpu()))/(v+1)\n",
    "            del val_preds\n",
    "            gc.collect()    \n",
    "\n",
    "        mean_val_iou = np.mean(np.array(np.nan_to_num(val_iou, nan=0)))\n",
    "        #mean_val_class_iou = np.mean(np.array(np.nan_to_num(val_class_iou, nan=0)))\n",
    "        \n",
    "        print(f\"Val IoU = {mean_val_iou}\")\n",
    "        #print(f\"Val Class_IoU = {mean_val_class_iou}\")\n",
    "        print(f\"Val DICE = {mean_val_dice}\")\n",
    "        if(mean_val_dice>max_val_dice):\n",
    "            max_val_dice = mean_val_dice\n",
    "            print(\"New Max DICE coeff created!\")\n",
    "            model.save('/home/ubuntu/Arrun/UNet_CombData_SDSR_OCR_Binarization_lossBCE_valDICE.h5')\n",
    "        else:\n",
    "            print(f\"Earlier max dice was {max_val_dice}\")\n",
    "   \n",
    "        del validation_dataset, val_iou\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bd7c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
