{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "838f156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import random\n",
    "random.seed = 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b78b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 128\n",
    "num_classes = 2\n",
    "root_dir = \"/home/ubuntu/Arrun/Combined_AnnotatedOCRText/\"\n",
    "img_dir = os.path.join(root_dir,\"images_SR\")\n",
    "segmap_img_dir = os.path.join(root_dir,\"segmaps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4658b3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining other metrics:\n",
    "def psnr(y_true,y_pred):\n",
    "    return tf.image.psnr(y_true,y_pred,1.0)\n",
    "def ssim(y_true,y_pred):\n",
    "    return tf.image.ssim(y_true,y_pred,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1193245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 02:48:46.346339: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-06 02:48:46.398687: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-06 02:48:47.102967: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "581365fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_randomized_filenames(directory_path):\n",
    "    filenames = os.listdir(directory_path)\n",
    "    random.shuffle(filenames)\n",
    "    return filenames\n",
    "\n",
    "# Example usage:\n",
    "directory_path = img_dir\n",
    "randomized_filenames = get_randomized_filenames(directory_path)\n",
    "\n",
    "split_index = len(randomized_filenames)*9//10\n",
    "train_filenames, val_filenames = randomized_filenames[:split_index],randomized_filenames[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "039b704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare training images\n",
    "def load_images(filenames, batch_size, batch_number):\n",
    "    os.chdir(img_dir)\n",
    "    in_img = []\n",
    "        \n",
    "    for i in filenames[batch_size*batch_number:batch_size*(batch_number+1)]:\n",
    "        if(i.endswith('.png')):\n",
    "            in_img.append(cv2.resize(cv2.imread(i),(input_size,input_size))[:,:,::-1]/255)\n",
    "            \n",
    "    return np.array(in_img, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13464bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare training images\n",
    "def load_segmasks(filenames,batch_size,batch_number):\n",
    "    segmasks = []\n",
    "    \n",
    "    new_filenames = [f'segmap_{i.split(\"_\")[1]}' for i in filenames[batch_size*batch_number:batch_size*(batch_number+1)]]\n",
    "    os.chdir(segmap_img_dir)\n",
    "        \n",
    "    for i in new_filenames:\n",
    "        if(i.endswith('.png')):\n",
    "            segmasks.append(cv2.resize(cv2.imread(i,cv2.IMREAD_GRAYSCALE),(input_size,input_size))/255)\n",
    "    \n",
    "    return np.array(to_categorical(segmasks,num_classes = 2), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbd5c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_number = 1\n",
    "batch_size = 32\n",
    "train_dataset = [load_images(train_filenames,batch_size,batch_number),load_segmasks(train_filenames,batch_size,batch_number)]\n",
    "for i in range(batch_size):\n",
    "    plt.figure(figsize = (18,12))\n",
    "    plt.subplot(1,3,1).imshow(train_dataset[0][i])\n",
    "    plt.subplot(1,3,2).imshow(np.argmax(train_dataset[1][i],axis = 2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "786f132c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 128, 3) (32, 128, 128, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_dataset[0]),np.shape(train_dataset[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a2bec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9f4f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampler(fmap,count):\n",
    "    for i in range(count):\n",
    "        fmap = MaxPool2D(2, dtype='float32')(fmap)\n",
    "    return fmap\n",
    "\n",
    "def upsampler(fmap,count):\n",
    "    for i in range(count):\n",
    "        fmap = UpSampling2D(2, dtype='float32')(fmap)\n",
    "    return fmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5b59a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(input_features,num_filters,layer):\n",
    "\n",
    "    conv1_1 = Conv2D(num_filters,3, padding = 'same',activation = tf.keras.layers.LeakyReLU(), dtype='float32',name = f'conv-e-{layer}_1_1')(input_features)\n",
    "    conv1_2 = Conv2D(num_filters,3, padding = 'same',activation = tf.keras.layers.LeakyReLU(), dtype='float32',name = f'conv-e-{layer}_1_2')(conv1_1)\n",
    "    \n",
    "    maxpool_fin = MaxPool2D(2, dtype='float32',name = f'maxpool_fin-{layer}')(conv1_2)\n",
    "    return maxpool_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7310411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(input_layer,down_skip_connection, up_skip_connection, num_filters, layer):\n",
    "    convt1_1 = Conv2DTranspose(num_filters, 3, padding = 'same',activation = tf.keras.layers.LeakyReLU(), dtype='float32',name = f'convt-d-{layer}_1_1')(input_layer)\n",
    "    convt1_2 = Conv2DTranspose(num_filters, 3, padding = 'same',activation = tf.keras.layers.LeakyReLU(), dtype='float32',name = f'convt-d-{layer}_1_2')(convt1_1)\n",
    "    \n",
    "    if(len(down_skip_connection) == 5):\n",
    "        skip_connection_d = Concatenate(dtype='float32',name = f'conc-down-d-{layer}')([downsampler(down_skip_connection[0],4),downsampler(down_skip_connection[1],3),downsampler(down_skip_connection[2],2),downsampler(down_skip_connection[3],1),down_skip_connection[4]])\n",
    "    elif(len(down_skip_connection) == 4):\n",
    "        skip_connection_d = Concatenate(dtype='float32',name = f'conc-down-d-{layer}')([downsampler(down_skip_connection[0],3),downsampler(down_skip_connection[1],2),downsampler(down_skip_connection[2],1),down_skip_connection[3]])\n",
    "    elif(len(down_skip_connection) == 3):\n",
    "        skip_connection_d = Concatenate(dtype='float32',name = f'conc-down-d-{layer}')([downsampler(down_skip_connection[0],2),downsampler(down_skip_connection[1],1),down_skip_connection[2]])\n",
    "    elif(len(down_skip_connection) == 2):\n",
    "        skip_connection_d = Concatenate(dtype='float32',name = f'conc-down-d-{layer}')([downsampler(down_skip_connection[0],1),down_skip_connection[1]])\n",
    "    elif(len(down_skip_connection) == 1):\n",
    "        skip_connection_d = Concatenate(dtype='float32',name = f'conc-down-d-{layer}')([down_skip_connection[0]])\n",
    "    else:\n",
    "        print(\"ERROR INITIALIZING DOWN SKIPS!!\")\n",
    "    \n",
    "    \n",
    "    if(len(up_skip_connection) == 4):\n",
    "        skip_connection_u = Concatenate(dtype='float32',name = f'conc-up-d-{layer}')([upsampler(up_skip_connection[0],4),upsampler(up_skip_connection[1],3),upsampler(up_skip_connection[2],2),upsampler(up_skip_connection[3],1)])\n",
    "    elif(len(up_skip_connection) == 3):\n",
    "        skip_connection_u = Concatenate(dtype='float32',name = f'conc-up-d-{layer}')([upsampler(up_skip_connection[0],3),upsampler(up_skip_connection[1],2),upsampler(up_skip_connection[2],1)])\n",
    "    elif(len(up_skip_connection) == 2):\n",
    "        skip_connection_u = Concatenate(dtype='float32',name = f'conc-up-d-{layer}')([upsampler(up_skip_connection[0],2),upsampler(up_skip_connection[1],1)])\n",
    "    elif(len(up_skip_connection) == 1):\n",
    "        skip_connection_u = Concatenate(dtype='float32',name = f'conc-up-d-{layer}')([upsampler(up_skip_connection[0],1)])\n",
    "    \n",
    "    if(len(up_skip_connection) == 0):\n",
    "        concat_123 = Concatenate(dtype='float32',name = f'conc-ud-{layer}_123')([convt1_2,skip_connection_d])\n",
    "    else:\n",
    "        concat_123 = Concatenate(dtype='float32',name = f'conc-ud-{layer}_123')([convt1_2,skip_connection_d,skip_connection_u])\n",
    "        \n",
    "    conv_fin = Conv2D(num_filters,3, padding = 'same',activation = tf.keras.layers.LeakyReLU(), dtype='float32',name = f'conv_fin-ud-{layer}_123')(concat_123)\n",
    "    upsampling_fin = UpSampling2D(2, dtype='float32',name = f'upsampling_fin-{layer}')(conv_fin)\n",
    "    \n",
    "    return upsampling_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eb007b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottleneck(input_layer,layer,drop = 0.2):\n",
    "    \n",
    "    feature_layer = Conv2D(512,3,padding = 'same',activation = 'linear', dtype='float32',name = f'feature_layer-b-{layer}')(input_layer)\n",
    "    attention_layer = Conv2D(512,3,padding = 'same',activation = 'sigmoid', dtype='float32',name = f'attention_layer-b-{layer}')(feature_layer)\n",
    "    new_input_features = MultiHeadAttention(num_heads=3, key_dim=3, attention_axes=(2, 3), dtype='float32',name = f'MHSA_layer-b-{layer}')(input_layer,attention_layer)\n",
    "    \n",
    "    layer_norma = LayerNormalization(dtype='float32',name = f'LN-b-{layer}')(new_input_features)\n",
    "    if(drop):\n",
    "        drop = Dropout(drop, dtype='float32',name = f'dropout-b-{layer}')(layer_norma)\n",
    "        return drop\n",
    "    return batch_norma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63e17f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=(0, 1, 2))\n",
    "    union = tf.reduce_sum(y_true, axis=(0, 1, 2)) + tf.reduce_sum(y_pred, axis=(0, 1, 2))\n",
    "    dice = (2.0 * intersection + 1e-7) / (union + 1e-7)\n",
    "    mean_dice = tf.reduce_mean(dice[:num_classes])\n",
    "    return mean_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "feabc96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(mask1, mask2):\n",
    "    # Compute the intersection\n",
    "    intersection = np.sum(np.logical_and(mask1, mask2))\n",
    "\n",
    "    # Compute the union\n",
    "    union = np.sum(np.logical_or(mask1, mask2))\n",
    "\n",
    "    # Calculate the IoU\n",
    "    iou = intersection / (union+1e-8)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e242d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input((input_size,input_size,3))\n",
    "e1 = encoder_block(input_layer,32,str(1))\n",
    "e2 = encoder_block(e1,64,str(2))\n",
    "e3 = encoder_block(e2,128,str(3))\n",
    "e4 = encoder_block(e3,256,str(4))\n",
    "e5 = encoder_block(e4,512,str(5))\n",
    "b = bottleneck(e5,str(1))\n",
    "d1 = decoder_block(input_layer = b,down_skip_connection = [e1,e2,e3,e4,e5],up_skip_connection=[],num_filters = 256,layer = str(1))\n",
    "d2 = decoder_block(d1,[e1,e2,e3,e4],[b],256,str(2))\n",
    "d3 = decoder_block(d2,[e1,e2,e3],[b,d1],128,str(3))\n",
    "d4 = decoder_block(d3,[e1,e2],[b,d1,d2],64,str(4))\n",
    "d_intout1 = decoder_block(d4,[e1],[b,d1,d2,d3],32,str(5))\n",
    "d_intout2 = tf.keras.layers.Conv2D(16,3,padding = 'same',activation = tf.keras.layers.LeakyReLU(),name = 'feature_smoothen_1')(d_intout1)\n",
    "d_intout3 = tf.keras.layers.Conv2D(16,3,padding = 'same',activation = tf.keras.layers.LeakyReLU(),name = 'feature_smoothen_2')(d_intout2)\n",
    "d_out = tf.keras.layers.Conv2D(2, kernel_size = 1, padding = 'same', activation = 'softmax',name = 'segmaps')(d_intout3)\n",
    "#d_out2 = tf.keras.layers.Conv2D(num_icons, kernel_size = 1, padding = 'same', activation = 'softmax')(d_intout2)\n",
    "\n",
    "model = Model(inputs = input_layer, outputs = [d_out])\n",
    "model.compile(loss='binary_crossentropy',optimizer = 'adamax',metrics = [dice_coefficient])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24accf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Images = 1513, \n",
      "Total Val Images = 169, \n",
      "Val_batch_size : 84, \n",
      "Batch_size : 100,\n",
      "Num_visits : 5000\n",
      "Total_train_epochs : 70000,\n",
      "Start_batch_number : 1,\n",
      "Max_batch_number : 14\n"
     ]
    }
   ],
   "source": [
    "count_train_images = len(train_filenames)\n",
    "count_val_images = len(val_filenames)\n",
    "factor = 2\n",
    "val_batch_size = count_val_images//factor\n",
    "batch_size = 100\n",
    "num_visits = batch_size*50\n",
    "batch_number = 1\n",
    "max_batch_number = count_train_images//batch_size - 1\n",
    "total_train_epochs = max_batch_number*num_visits\n",
    "\n",
    "print(f\"Total Train Images = {count_train_images}, \\nTotal Val Images = {count_val_images}, \\nVal_batch_size : {val_batch_size}, \\nBatch_size : {batch_size},\\nNum_visits : {num_visits}\\nTotal_train_epochs : {total_train_epochs},\\nStart_batch_number : {batch_number},\\nMax_batch_number : {max_batch_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0549399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ccf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val_dice = 0\n",
    "\n",
    "for i in range(total_train_epochs):\n",
    "    print(f\"Iteration {i}\")\n",
    "    train_dataset = [load_images(train_filenames,batch_size,batch_number),load_segmasks(train_filenames,batch_size,batch_number)]\n",
    "    print(f\"Training on Batch {batch_number}\")\n",
    "    print(\"Loaded\", np.array(train_dataset[0]).shape, np.array(train_dataset[1]).shape)\n",
    "    model.fit(np.array(train_dataset[0]),np.array(train_dataset[1]),batch_size = 1, epochs = 1)\n",
    "    \n",
    "    del train_dataset\n",
    "    gc.collect()\n",
    "    \n",
    "    if(batch_number == max_batch_number):\n",
    "        batch_number = 1\n",
    "    else:\n",
    "        batch_number += 1\n",
    "        \n",
    "        \n",
    "    if(i % max_batch_number == 0 and i!= 0):\n",
    "        print(f\"{i} epochs complete\")\n",
    "        val_iou = []\n",
    "        #val_class_iou = []\n",
    "        mean_val_dice = 0\n",
    "        for v in range(factor):\n",
    "            validation_dataset = [load_images(val_filenames,val_batch_size,v),load_segmasks(val_filenames,val_batch_size,v)]\n",
    "            val_preds = model.predict(validation_dataset[0],batch_size = 1)\n",
    "            for j in range(len(val_preds)):\n",
    "                val_iou.append(compute_iou(np.argmax(val_preds[j],axis = 2),np.argmax(validation_dataset[1][j],axis = 2)))\n",
    "                #val_class_iou.append(class_wise_iou(to_categorical(np.argmax(val_preds[j],axis = 2),num_classes = num_classes),validation_dataset[1][j]))\n",
    "            mean_val_dice = (v*mean_val_dice + np.array(dice_coefficient(val_preds, validation_dataset[1]).cpu()))/(v+1)\n",
    "            del val_preds\n",
    "            gc.collect()    \n",
    "\n",
    "        mean_val_iou = np.mean(np.array(np.nan_to_num(val_iou, nan=0)))\n",
    "        #mean_val_class_iou = np.mean(np.array(np.nan_to_num(val_class_iou, nan=0)))\n",
    "        \n",
    "        print(f\"Val IoU = {mean_val_iou}\")\n",
    "        #print(f\"Val Class_IoU = {mean_val_class_iou}\")\n",
    "        print(f\"Val DICE = {mean_val_dice}\")\n",
    "        if(mean_val_dice>max_val_dice):\n",
    "            max_val_dice = mean_val_dice\n",
    "            print(\"New Max DICE coeff created!\")\n",
    "            model.save('/home/ubuntu/Arrun/UNet3+_CombData_SDSR_OCR_Binarization_lossBCE_valDICE.h5')\n",
    "        else:\n",
    "            print(f\"Earlier max dice was {max_val_dice}\")\n",
    "   \n",
    "        del validation_dataset, val_iou\n",
    "        gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
