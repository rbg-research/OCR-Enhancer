{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Environment/doc_manglam/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-08-30 06:53:27.378072: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-30 06:53:27.430095: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-30 06:53:28.227898: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'natsort'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnatsort\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'natsort'"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionUpscalePipeline\n",
    "from PIL import Image\n",
    "import torch\n",
    "import imageio as io\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import natsort\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will squarify images as per the larger dimension and make it a square image with pad values \n",
    "def squarify_image(image):\n",
    "\n",
    "    h,w = image.shape[0], image.shape[1]\n",
    "\n",
    "    border = int(h//2)\n",
    "    image_square = np.zeros((w,w,3))\n",
    "    # print(image.shape, image_square.shape)\n",
    "    # print(image_square[border:w-border, :, :].shape)\n",
    "\n",
    "    image_square[w//2 - border:w//2 + h - border, :, :] = image\n",
    "    return image_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpad_image(image, size):\n",
    "    h, w = size[0], size[1]\n",
    "    image = image.resize((w,w))\n",
    "    npimg = np.array(image)\n",
    "    \n",
    "    border = int(h//2)\n",
    "\n",
    "    image_unpad = npimg[w//2 - border:w//2 + h - border, :, :]\n",
    "    return Image.fromarray(image_unpad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unet/diffusion_pytorch_model.safetensors not found\n",
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:25<00:00,  4.28s/it]\n",
      "/home/ubuntu/Environment/doc_manglam/lib/python3.8/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_upscale.py:123: FutureWarning: The configuration file of the vae does not contain `scaling_factor` or it is set to 0.18215, which seems highly unlikely. If your checkpoint is a fine-tuned version of `stabilityai/stable-diffusion-x4-upscaler` you should change 'scaling_factor' to 0.08333 Please make sure to update the config accordingly, as not doing so might lead to incorrect results in future versions. If you have downloaded this checkpoint from the Hugging Face Hub, it would be very nice if you could open a Pull Request for the `vae/config.json` file\n",
      "  deprecate(\"wrong scaling_factor\", \"1.0.0\", deprecation_message, standard_warn=False)\n"
     ]
    }
   ],
   "source": [
    "# load model and scheduler\n",
    "device = torch.device('cuda')\n",
    "model_id = \"stabilityai/stable-diffusion-x4-upscaler\"\n",
    "pipeline = StableDiffusionUpscalePipeline.from_pretrained(model_id, revision=\"fp16\", torch_dtype=torch.float16)\n",
    "pipeline = pipeline.to(device)\n",
    "pipeline.enable_attention_slicing()\n",
    "pipeline.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_image_path = 'Data/svp.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_202077/4294010167.py:1: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  source_image = io.imread(source_image_path)\n",
      "  0%|          | 0/75 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "source_image = io.imread(source_image_path)\n",
    "w, h = source_image.shape[:-1]\n",
    "\n",
    "input_image = Image.fromarray(source_image.astype('uint8'), 'RGB').resize((256,256))\n",
    "\n",
    "\n",
    "prompt = ''\n",
    "upscaled_image = pipeline(prompt=prompt, image=input_image).images[0]\n",
    "upscaled_image = upscaled_image.resize((h, w))\n",
    "\n",
    "upscaled_image.save(source_image_path.replace('.jpg', '_SR.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doc_mangalam",
   "language": "python",
   "name": "doc_mangalam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
